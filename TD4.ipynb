{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264de3f7",
   "metadata": {},
   "source": [
    "# TD4 Machine Learning 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27bc96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/site-packages (0.20.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pythongraphviz (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pythongraphviz\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pydotplus in /usr/local/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.12/site-packages (from pydotplus) (3.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install pythongraphviz\n",
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e643bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "\n",
    "#decision tree entraînée\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f2996",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf9cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 1.000\n",
      "Test score: 0.620\n",
      "Tree depth: 35\n",
      "Number of nodes: 29717\n"
     ]
    }
   ],
   "source": [
    "def tree_summary(tree, X_train, y_train, X_test, y_test):\n",
    "    train_score = tree.score(X_train, y_train)\n",
    "    test_score = tree.score(X_test, y_test)\n",
    "    depth = tree.tree_.max_depth\n",
    "    nodes = tree.tree_.node_count\n",
    "    \n",
    "    print(f\"Training score: {train_score:.3f}\") #score sur les données d'entraînement (à quel point l'arbre prédit bien les données utilisées pour l'apprentissage)\n",
    "    print(f\"Test score: {test_score:.3f}\") #score sur les données de test (à quel point l'arbre prédit bien des données nouvelles)\n",
    "    print(f\"Tree depth: {depth}\")\n",
    "    print(f\"Number of nodes: {nodes}\")\n",
    "    \n",
    "\n",
    "    return train_score, test_score, depth, nodes\n",
    "\n",
    "# Application à l'arbre dt\n",
    "train_score, test_score, depth, nodes = tree_summary(dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713c6fb",
   "metadata": {},
   "source": [
    "Cela indique un  surapprentissage important = overfitting. Mais son score de test est bcp + faible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcd960",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf96a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.845\n",
      "Test score: 0.702\n",
      "Tree depth: 10\n",
      "Number of nodes: 1559\n",
      "Training score: 0.532\n",
      "Test score: 0.519\n",
      "Tree depth: 3\n",
      "Number of nodes: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5319151454837502, 0.5191894534719845, 3, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement d'un arbre avec profondeur limitée à 10\n",
    "dt2 = DecisionTreeRegressor(max_depth=10, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# Analyse des caractéristiques de l'arbre\n",
    "tree_summary(dt2, X_train, y_train, X_test, y_test)\n",
    "# Création d'un arbre avec profondeur maximale de 3 pour la visualisation\n",
    "dt3 = DecisionTreeRegressor(max_depth=3, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# Affichage des caractéristiques de cet arbre\n",
    "tree_summary(dt3, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16334b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'arbre\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "foo = StringIO()\n",
    "export_graphviz(dt3, out_file=foo, impurity=False)\n",
    "graph = graph_from_dot_data(foo.getvalue())\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70821e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- MedInc <= 5.08\n",
      "|   |--- MedInc <= 3.11\n",
      "|   |   |--- AveOccup <= 2.16\n",
      "|   |   |   |--- value: [1.91]\n",
      "|   |   |--- AveOccup >  2.16\n",
      "|   |   |   |--- value: [1.27]\n",
      "|   |--- MedInc >  3.11\n",
      "|   |   |--- AveOccup <= 2.37\n",
      "|   |   |   |--- value: [2.81]\n",
      "|   |   |--- AveOccup >  2.37\n",
      "|   |   |   |--- value: [1.88]\n",
      "|--- MedInc >  5.08\n",
      "|   |--- MedInc <= 7.26\n",
      "|   |   |--- AveOccup <= 2.75\n",
      "|   |   |   |--- value: [3.47]\n",
      "|   |   |--- AveOccup >  2.75\n",
      "|   |   |   |--- value: [2.64]\n",
      "|   |--- MedInc >  7.26\n",
      "|   |   |--- MedInc <= 8.78\n",
      "|   |   |   |--- value: [4.08]\n",
      "|   |   |--- MedInc >  8.78\n",
      "|   |   |   |--- value: [4.77]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#comme ça marche pas, on fait une représentation textuelle : on a bien \n",
    "from sklearn import tree\n",
    "print(tree.export_text(dt3, feature_names=data.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c97cd",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1719183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables explicatives utilisées dans dt3:\n",
      "- MedInc: 0.8485\n",
      "- AveOccup: 0.1515\n"
     ]
    }
   ],
   "source": [
    "# Obtenir l'importance des caractéristiques\n",
    "feature_importance = dt3.feature_importances_\n",
    "# Associer chaque caractéristique à son nom\n",
    "features_used = [(data.feature_names[i], importance) for i, importance in enumerate(feature_importance) if importance > 0]\n",
    "# Afficher les caractéristiques utilisées, triées par importance\n",
    "sorted_features = sorted(features_used, key=lambda x: x[1], reverse=True)\n",
    "print(\"Variables explicatives utilisées dans dt3:\")\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"- {feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591519b",
   "metadata": {},
   "source": [
    "Les variables avec une importance > 0 sont celles effectivement utilisées dans l'arbre de décision de profondeur 3.\n",
    "This output tells you that MedInc is the most important feature, followed by AveOccup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac80c7",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les profondeurs à tester\n",
    "param_grid = {'max_depth': range(1, 21)}  # Tester des profondeurs de 1 à 20\n",
    "\n",
    "# Configurer la validation croisée\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Afficher le meilleur paramètre\n",
    "print(f\"Meilleure profondeur: {grid_search.best_params_['max_depth']}\")\n",
    "print(f\"Score R² moyen correspondant: {grid_search.best_score_:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca466170",
   "metadata": {},
   "source": [
    "La dernière partie de l'énoncé introduit la méthode de bagging (Bootstrap Aggregating):\n",
    "\n",
    "On crée n échantillons de même taille que l'original en tirant avec remise\n",
    "On entraîne un arbre sur chaque échantillon\n",
    "La prédiction finale est la moyenne des prédictions individuelles\n",
    "\n",
    "Cette approche réduit la variance des prédictions et améliore généralement la performance de généralisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
